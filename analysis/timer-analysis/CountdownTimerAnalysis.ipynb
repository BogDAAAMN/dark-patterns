{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect countdown timers using heuristics based on segment updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import dirname, abspath, join, isfile\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "pd.options.display.html.use_mathjax = False\n",
    "\n",
    "TIMER_MIN_NEG_POS_UPDATE_RATIO = 5  # there should be 5X more -ve updates than +ve\n",
    "TIMER_MIN_NO_OF_NEG_UPDATES = 5  # there should be 5 or more decreases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENTS_QUERY = '''\n",
    "    SELECT sv.site_url, sv.visit_id, se.node_id,\n",
    "        se.top, se.left, se.width, se.height, se.inner_text, se.time_stamp\n",
    "        FROM SEGMENTS as se LEFT JOIN site_visits as sv ON se.visit_id = sv.visit_id\n",
    "        WHERE se.node_name != 'BODY' and se.inner_text GLOB '*[0-9]*';\n",
    "    '''\n",
    "\n",
    "def load_segments(crawler_name, check_cache=True, dump_pickle=True):\n",
    "    assert crawler_name in [\"odin\", \"webtap\"]\n",
    "    pickle_file = \"%s_segments.pickle\" % crawler_name\n",
    "\n",
    "    # load already pickled segments\n",
    "    if check_cache and isfile(pickle_file):\n",
    "        print(\"Will load segments from pickle %s\" % pickle_file)\n",
    "        return pd.read_pickle(pickle_file)\n",
    "\n",
    "    final_crawl_dir = join(dirname(dirname(os.getcwd())), 'data', 'final-crawl')\n",
    "    db_path = join(final_crawl_dir, \"%s.sqlite\" % crawler_name)\n",
    "    con = sqlite3.connect(db_path)\n",
    "    segments = pd.read_sql_query(SEGMENTS_QUERY, con)\n",
    "    if dump_pickle:\n",
    "        segments.to_pickle(pickle_file)\n",
    "    return segments\n",
    "\n",
    "def preprocess_segments(segments):\n",
    "    \"\"\"Add headers for analysis.\"\"\"\n",
    "    segments['time_stamp'] = pd.to_datetime(segments['time_stamp'])\n",
    "    # replace digits/numbers with DPNUM\n",
    "    segments['inner_processed'] = segments['inner_text'].map(lambda x: re.sub(r'\\d+', 'DPNUM', x))\n",
    "    # remove non-digits\n",
    "    segments['inner_digits'] = segments['inner_text'].map(lambda x: re.sub(r'\\D+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_with_comma(series):\n",
    "    return reduce(lambda x, y: x + \",\" + y, series)\n",
    "\n",
    "def differences(series):\n",
    "    \"\"\"Return differences between the elements of a series.\"\"\" \n",
    "    return [int(j)-int(i) for i, j in zip(series[:-1], series[1:])]\n",
    "\n",
    "def time_differences(series):\n",
    "    \"\"\"Return differences in seconds between the elements of a series.\"\"\"\n",
    "    return [(j-i).total_seconds() for i, j in zip(series[:-1], series[1:])]\n",
    "\n",
    "def most_common(diffs):\n",
    "    \"\"\"Return the most common number of an iterable.\"\"\"\n",
    "    if not diffs: return None\n",
    "    return Counter(diffs).most_common(1)[0][0]\n",
    "\n",
    "def most_common_neg(diffs):\n",
    "    \"\"\"Return the most common negative number of an iterable.\"\"\"\n",
    "    if not diffs: return None\n",
    "    neg_diffs = [x for x in diffs if x <0]\n",
    "    if not neg_diffs: return None\n",
    "    return Counter(neg_diffs).most_common(1)[0][0]\n",
    "\n",
    "def num_most_common_neg(diffs):\n",
    "    \"\"\"Return the number of times the most common negative number occurs.\"\"\"\n",
    "    neg_mode = most_common_neg(diffs)\n",
    "    if not neg_mode: return 0\n",
    "    return diffs.count(neg_mode)\n",
    "\n",
    "\n",
    "def is_decreasing(series):\n",
    "    \"\"\"Heuristic to determine whether a series is decreasing.\n",
    "    \n",
    "    We expect 5 decreasing updates to the timer and the\n",
    "    number of negative updates must 5 times more than the positive ones.\"\"\"\n",
    "    diffs = differences(series)\n",
    "    if not diffs: return False\n",
    "    # 10->09, 00->59\n",
    "    n_negs = sum([1 for diff in diffs if diff<0 and diff not in [59, 5, 9]])\n",
    "    n_pos = sum([1 for diff in diffs if diff>0])\n",
    "    n_zeroes = diffs.count(0)\n",
    "    if n_negs < TIMER_MIN_NO_OF_NEG_UPDATES: return False  # fewer than 5 decreasing updates\n",
    "    if not n_pos: return True\n",
    "    return float(n_negs) / n_pos > TIMER_MIN_NEG_POS_UPDATE_RATIO\n",
    "\n",
    "\n",
    "def is_decreasing_mode(series):\n",
    "    \"\"\"Heuristic to determine whether a series is decreasing using mode.\n",
    "    \n",
    "    We expect the following:\n",
    "    - more than 5 negative updates\n",
    "    - mode of the differences should be negative and it should occur more than 5 times\n",
    "    - more negative updates than the positive updates\n",
    "\n",
    "    \"\"\"\n",
    "    diffs = differences(series)\n",
    "    if not diffs: return False\n",
    "    # to few updates\n",
    "    if len(set(series)) < 5: return False\n",
    "    # 10->09, 00->59\n",
    "    n_negs = sum([1 for diff in diffs if diff<0 and diff not in [59, 5, 9]])\n",
    "    n_pos = sum([1 for diff in diffs if diff>0])\n",
    "    n_zeroes = diffs.count(0)\n",
    "    if n_negs < TIMER_MIN_NO_OF_NEG_UPDATES: return False  # fewer than 5 decreasing updates\n",
    "    if not n_pos: return True\n",
    "    mode = most_common(diffs)\n",
    "    # mode should be negative\n",
    "    if mode > 0: return False\n",
    "    neg_mode_cnt = num_most_common_neg(diffs)\n",
    "    # mode should occur more than 5 times\n",
    "    if neg_mode_cnt < 5: return False\n",
    "    # number of negative updates should be more than the positive updates\n",
    "    return n_negs > n_pos\n",
    "\n",
    "\n",
    "def num_unique(series):\n",
    "    return len(set(series))\n",
    "\n",
    "\n",
    "def ts_check(series):\n",
    "    \"\"\"Check whether we got updates on 5 distinct seconds.\"\"\"\n",
    "    n_uniq_ts_seconds = len(set([int(ts) for ts in series]))\n",
    "    return n_uniq_ts_seconds >= 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_timers(segments, limit=None):\n",
    "    tmp = segments\n",
    "    if limit:\n",
    "        tmp = segments.head(limit)\n",
    "    segments_grouped = tmp.\\\n",
    "        groupby(['visit_id', 'top', 'left', 'inner_processed'], as_index=False).\\\n",
    "        agg({'node_id': num_unique,\n",
    "             'time_stamp': ts_check,\n",
    "             'inner_digits': [is_decreasing, is_decreasing_mode], 'site_url': 'first'})\n",
    "    segments_grouped.columns = segments_grouped.columns.map('_'.join)\n",
    "    timers = segments_grouped[segments_grouped.inner_digits_is_decreasing &\n",
    "                              segments_grouped.inner_digits_is_decreasing_mode &\n",
    "                              segments_grouped.time_stamp_ts_check]\n",
    "    return timers, segments_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_timer_urls(timers, crawler_name):\n",
    "    pd.Series(timers.site_url_first.unique()).\\\n",
    "        to_csv(\"%s_timer_urls.csv\" % crawler_name, sep='\\t', index=False)\n",
    "    \n",
    "\n",
    "def get_timers(crawler_name, disable_cache=False):\n",
    "    pickle_path = \"%s_grouped_segments.pickle\" % crawler_name\n",
    "    if isfile(pickle_path) and not disable_cache:\n",
    "        print(\"Will load grouped segments from pickle %s\" % pickle_path)\n",
    "        grouped_segments = pd.read_pickle(pickle_path)\n",
    "        timers = grouped_segments[\n",
    "            grouped_segments.inner_digits_is_decreasing &\n",
    "            grouped_segments.inner_digits_is_decreasing_mode &\n",
    "            grouped_segments.time_stamp_ts_check]\n",
    "        return timers, grouped_segments\n",
    "    else:\n",
    "        segments = load_segments(crawler_name)\n",
    "        preprocess_segments(segments)\n",
    "        timers, grouped_segments = detect_timers(segments)\n",
    "        dump_timer_urls(timers, crawler_name)\n",
    "        grouped_segments.to_pickle(pickle_path)\n",
    "        return timers, grouped_segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run timer detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will load grouped segments from pickle webtap_grouped_segments.pickle\n",
      "Will load grouped segments from pickle odin_grouped_segments.pickle\n"
     ]
    }
   ],
   "source": [
    "webtap_timers, webtap_segments_grouped = get_timers(\"webtap\")\n",
    "odin_timers, odin_segments_grouped = get_timers(\"odin\")\n",
    "all_timers = pd.concat([webtap_timers, odin_timers])\n",
    "all_segments_grouped = pd.concat([webtap_segments_grouped, odin_segments_grouped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1618"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_timers.site_url_first.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_timers.sort_values(\n",
    "    'site_url_first')[['visit_id_', 'top_', 'left_', 'site_url_first']].to_csv(\n",
    "    \"timer_coords.csv\", sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle grouped segments for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = list(all_timers.site_url_first.unique())\n",
    "all_urls.sort()\n",
    "pd.Series(all_urls).to_csv(\"timer_urls.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_CSV_CNT=8\n",
    "for num, urls in enumerate(np.array_split(all_urls, URL_CSV_CNT)):\n",
    "    pd.Series(urls).to_csv(\"timer_urls_%d.csv\" % (num+1), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1618 timer_urls.csv\n",
      "   203 timer_urls_1.csv\n",
      "   203 timer_urls_2.csv\n",
      "   202 timer_urls_3.csv\n",
      "   202 timer_urls_4.csv\n",
      "   202 timer_urls_5.csv\n",
      "   202 timer_urls_6.csv\n",
      "   202 timer_urls_7.csv\n",
      "   202 timer_urls_8.csv\n",
      "  1836 timer_urls_v2.csv\n",
      "  5072 total\n"
     ]
    }
   ],
   "source": [
    "! wc -l  timer_urls*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599\n",
      "1651\n",
      "1593\n",
      "1589\n"
     ]
    }
   ],
   "source": [
    "## The effect of different approaches\n",
    "print all_segments_grouped[all_segments_grouped.inner_digits_is_decreasing].visit_id_.nunique()\n",
    "print all_segments_grouped[all_segments_grouped.inner_digits_is_decreasing_mode].visit_id_.nunique()\n",
    "print all_segments_grouped[all_segments_grouped.inner_digits_is_decreasing & all_segments_grouped.inner_digits_is_decreasing_mode].visit_id_.nunique()\n",
    "print all_timers.visit_id_.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_id_</th>\n",
       "      <th>top_</th>\n",
       "      <th>left_</th>\n",
       "      <th>inner_processed_</th>\n",
       "      <th>time_stamp_ts_check</th>\n",
       "      <th>node_id_num_unique</th>\n",
       "      <th>site_url_first</th>\n",
       "      <th>inner_digits_is_decreasing</th>\n",
       "      <th>inner_digits_is_decreasing_mode</th>\n",
       "      <th>inner_digits_is_decreasing_relaxed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>41</td>\n",
       "      <td>145</td>\n",
       "      <td>290</td>\n",
       "      <td>Your order is reserved for DPNUM:DPNUM minutes!</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.anarchiststate.com/collections/top/products/what-is-truth-winter-jacket</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>41</td>\n",
       "      <td>621</td>\n",
       "      <td>923</td>\n",
       "      <td>DPNUM\\nHours\\n\\t\\nDPNUM\\nMinutes\\n\\t\\nDPNUM\\nDPNUM\\nSeconds</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.anarchiststate.com/collections/top/products/what-is-truth-winter-jacket</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6472</th>\n",
       "      <td>133</td>\n",
       "      <td>677</td>\n",
       "      <td>1214</td>\n",
       "      <td>Order in the next \\nDPNUM\\nhrs\\nDPNUM\\nmins\\nDPNUM\\nsec for free Friday delivery</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.printerbase.co.uk/canon-6431b001-pgi-550pgbk-xl-high-yield-black-pigment-ink-cartridge.html</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7757</th>\n",
       "      <td>161</td>\n",
       "      <td>517</td>\n",
       "      <td>924</td>\n",
       "      <td>Order within DPNUM hrs, DPNUM mins and DPNUM secs for delivery on Friday DPNUMth February</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.larizia.com/sale-c319/anya-hindmarch-circulus-mini-vere-silver-metallic-leather-barrel-bag-p90261</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10700</th>\n",
       "      <td>207</td>\n",
       "      <td>322</td>\n",
       "      <td>268</td>\n",
       "      <td>Check out now for an extra DPNUM% off!\\nUse the discount code: FAST. Expires in DPNUM:DPNUM minutes.</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>https://faradayscienceshop.com/collections/van-go-paint-by-number-kits/products/fall-van-go-paint-by-number-kit</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       visit_id_  top_  left_  \\\n",
       "1827          41   145    290   \n",
       "1835          41   621    923   \n",
       "6472         133   677   1214   \n",
       "7757         161   517    924   \n",
       "10700        207   322    268   \n",
       "\n",
       "                                                                                           inner_processed_  \\\n",
       "1827                                                        Your order is reserved for DPNUM:DPNUM minutes!   \n",
       "1835                                            DPNUM\\nHours\\n\\t\\nDPNUM\\nMinutes\\n\\t\\nDPNUM\\nDPNUM\\nSeconds   \n",
       "6472                       Order in the next \\nDPNUM\\nhrs\\nDPNUM\\nmins\\nDPNUM\\nsec for free Friday delivery   \n",
       "7757              Order within DPNUM hrs, DPNUM mins and DPNUM secs for delivery on Friday DPNUMth February   \n",
       "10700  Check out now for an extra DPNUM% off!\\nUse the discount code: FAST. Expires in DPNUM:DPNUM minutes.   \n",
       "\n",
       "       time_stamp_ts_check  node_id_num_unique  \\\n",
       "1827                  True                   1   \n",
       "1835                  True                   1   \n",
       "6472                  True                   1   \n",
       "7757                  True                   3   \n",
       "10700                 True                   1   \n",
       "\n",
       "                                                                                                        site_url_first  \\\n",
       "1827                               https://www.anarchiststate.com/collections/top/products/what-is-truth-winter-jacket   \n",
       "1835                               https://www.anarchiststate.com/collections/top/products/what-is-truth-winter-jacket   \n",
       "6472           https://www.printerbase.co.uk/canon-6431b001-pgi-550pgbk-xl-high-yield-black-pigment-ink-cartridge.html   \n",
       "7757     https://www.larizia.com/sale-c319/anya-hindmarch-circulus-mini-vere-silver-metallic-leather-barrel-bag-p90261   \n",
       "10700  https://faradayscienceshop.com/collections/van-go-paint-by-number-kits/products/fall-van-go-paint-by-number-kit   \n",
       "\n",
       "       inner_digits_is_decreasing  inner_digits_is_decreasing_mode  \\\n",
       "1827                         True                             True   \n",
       "1835                         True                             True   \n",
       "6472                         True                             True   \n",
       "7757                         True                             True   \n",
       "10700                        True                             True   \n",
       "\n",
       "       inner_digits_is_decreasing_relaxed  \n",
       "1827                                 True  \n",
       "1835                                 True  \n",
       "6472                                 True  \n",
       "7757                                 True  \n",
       "10700                                True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_timers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
