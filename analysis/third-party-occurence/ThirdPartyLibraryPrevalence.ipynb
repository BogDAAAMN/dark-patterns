{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third party ADP library prevalence analysis\n",
    "- Find the number sites that embed a given script/endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For third-party scripts: we use script domains (PS+1) to measure the prevalence.\n",
    "# For Wordpress and Magenta plugins served from first-party sites, we match the URL path.\n",
    "\n",
    "ADP_PROVIDER_DOMAINS = {\n",
    "    \"Fomo\": \"fomo.com\",\n",
    "    \"Beeketing\": \"beeketing.com\",\n",
    "    \"Recently\": \"appifiny.io\",\n",
    "    \"Fera\": \"fera.ai\",\n",
    "    \"Vitals\": \"getvitals.io\",\n",
    "    \"Nice (Shopify plugin)\": \"goldendev.win\",\n",
    "    \"LeanConvert\": \"lc-api.net\",\n",
    "    \"Taggstar\": \"taggstar.com\",\n",
    "    \"Insider\": \"useinsider.com\",\n",
    "    \"FreshRelevance\": \"dn1i8v75r669j.cloudfront.net\",\n",
    "    \"Qubit\": \"goqubit.com\",\n",
    "    \"Bunting\": \"bunting.com\",\n",
    "    \"ConvertCart\": \"convertcart.com\",\n",
    "    \"Proof\": \"useproof.com\",\n",
    "    \"Convertize\": \"convertize.io\",\n",
    "    \"Credibly\": \"credibly.io\",\n",
    "    \"DynamicYield\": \"dynamicyield.com\",\n",
    "    \"Bizzy\": \"pxu-recent-sales-apps.s3.amazonaws.com\",\n",
    "    \"Exponea\": \"exponea.com\",\n",
    "    \"Yieldify\": \"yieldify.com\"\n",
    "    # plugins\n",
    "    \"Amasty (Magento plugin)\": \"#amwhatsup/block/getlastactivity\",\n",
    "    \"Boost (Wordpress plugin)\": \"#plugins/boost/public/js/boost\",\n",
    "    \"Woocommerce Notification (Woocommerce plugin)\": \"#plugins/woocommerce-notification\",\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from urlparse import urlparse\n",
    "from os.path import expanduser\n",
    "from extract_tp_to_site_mapping import get_tld_or_host\n",
    "pd.set_option(\"display.max_colwidth\",500)\n",
    "pd.set_option(\"display.max_rows\",500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_as_json(obj, json_path):\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(obj, f)\n",
    "\n",
    "def load_json_file(json_path):\n",
    "    with open(json_path) as json_file:\n",
    "        return json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_sites_by_regex(endpoint_regexes, db_path):\n",
    "    con = sqlite3.connect(db_path)\n",
    "    con.row_factory = sqlite3.Row\n",
    "    query = \"\"\"SELECT sv.visit_id, sv.site_url, r.url, r.method,\n",
    "                r.post_body FROM http_requests as r LEFT JOIN site_visits as sv\n",
    "                ON sv.visit_id = r.visit_id\n",
    "                \"\"\"\n",
    "    adp_sites = defaultdict(set)\n",
    "    # print(\"Will run the query %s \" % query)\n",
    "    for row in con.execute(query):\n",
    "        for endpoint_name, endpoint_regex in endpoint_regexes.iteritems():\n",
    "            if re.search(endpoint_regex, row['url'].split(\"://\")[-1]):\n",
    "                host = urlparse(row['site_url']).hostname\n",
    "                # print host, row['site_url']\n",
    "                adp_sites[endpoint_name].add(host)\n",
    "\n",
    "    return adp_sites\n",
    "\n",
    "\n",
    "def get_embedding_sites(url_substrings, db_path):\n",
    "    con = sqlite3.connect(db_path)\n",
    "    con.row_factory = sqlite3.Row\n",
    "    query = \"\"\"SELECT sv.visit_id, sv.site_url, r.url, r.method,\n",
    "                r.post_body FROM http_requests as r LEFT JOIN site_visits as sv\n",
    "                ON sv.visit_id = r.visit_id\"\"\"\n",
    "    adp_sites = defaultdict(set)\n",
    "    # print(\"Will run the query %s \" % query)\n",
    "    for row in con.execute(query):\n",
    "        for js_url in url_substrings:\n",
    "            if js_url in row['url']:\n",
    "                host = urlparse(row['site_url']).hostname\n",
    "                # print host, row['site_url']\n",
    "                adp_sites[js_url].add(host)\n",
    "\n",
    "    return adp_sites\n",
    "\n",
    "def get_embedding_sites_by_domain(endpoint_patterns, db_path):\n",
    "    con = sqlite3.connect(db_path)\n",
    "    con.row_factory = sqlite3.Row\n",
    "    query = \"\"\"SELECT sv.visit_id, sv.site_url, r.url FROM\n",
    "                http_requests as r LEFT JOIN site_visits as sv\n",
    "                ON sv.visit_id = r.visit_id\n",
    "                \"\"\"\n",
    "    adp_sites = defaultdict(set)\n",
    "    # print(\"Will run the query %s \" % query)\n",
    "    for row in con.execute(query):\n",
    "        for endpoint_name, endpoint_pattern in endpoint_patterns.iteritems():\n",
    "            if endpoint_pattern.startswith(\"#\"):\n",
    "                endpoint_pattern = endpoint_pattern.strip(\"#\")\n",
    "                if endpoint_pattern in row['url']:\n",
    "                    host = urlparse(row['site_url']).hostname\n",
    "                    adp_sites[endpoint_name].add(host)\n",
    "            else:\n",
    "                req_tld = get_tld_or_host(row['url'])\n",
    "                if req_tld == endpoint_pattern:\n",
    "                    host = urlparse(row['site_url']).hostname\n",
    "                    adp_sites[endpoint_name].add(host)\n",
    "\n",
    "    return adp_sites\n",
    "\n",
    "def get_prevalence_counts(endpoint_patterns, db_path, db_path_2=None):\n",
    "    adp_sites_db = get_embedding_sites_by_domain(endpoint_patterns, db_path)\n",
    "    if db_path_2:\n",
    "        adp_sites_db_2 = get_embedding_sites_by_domain(endpoint_patterns, db_path_2)\n",
    "        for endpoint_name, sites in adp_sites_db_2.iteritems():\n",
    "            adp_sites_db[endpoint_name] |= sites\n",
    "    adp_prevalence = {endpoint_name: len(sites) for endpoint_name, sites in adp_sites_db.iteritems()}\n",
    "    return adp_prevalence, adp_sites_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute third party prevalence using data from the checkout crawls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to checkout crawls\n",
    "ODIN_DB_PATH = \"/mnt/10tb4/dark-patterns-databases/odin/odin.sqlite\"\n",
    "WEBTAP_DB_PATH = \"/mnt/10tb4/dark-patterns-databases/webtap/webtap.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adp_prevalence, adp_sites_dict = get_prevalence_counts(ADP_PROVIDER_DOMAINS, ODIN_DB_PATH, WEBTAP_DB_PATH)\n",
    "dump_as_json(adp_prevalence, \"adp-third-party-lib-prevalence-odin-webtap-regex.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beeketing 406\n",
      "DynamicYield 114\n",
      "Yieldify 111\n",
      "Fomo 91\n",
      "FreshRelevance 86\n",
      "Insider 52\n",
      "Bizzy 33\n",
      "ConvertCart 31\n",
      "Taggstar 27\n",
      "Qubit 25\n",
      "Exponea 18\n",
      "Recently 14\n",
      "Proof 11\n",
      "Fera 11\n",
      "Nice (Shopify plugin) 10\n",
      "Woocommerce Notification (Woocommerce plugin) 10\n",
      "Bunting 5\n",
      "Credibly 4\n",
      "Convertize 3\n",
      "LeanConvert 2\n",
      "Amasty (Magento plugin) 1\n",
      "Boost (Wordpress plugin) 1\n"
     ]
    }
   ],
   "source": [
    "for endpoint_name, site_count in sorted(adp_prevalence.iteritems(), key=lambda x: x[1], reverse=True): \n",
    "    print endpoint_name, site_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute prevalence using data from Princeton Web Census 1-million Site Crawl\n",
    "- We used the November 2018 crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beeketing 4151\n",
      "Fomo 663\n",
      "Proof 508\n",
      "Insider 484\n",
      "DynamicYield 416\n",
      "Yieldify 323\n",
      "Bizzy 213\n",
      "FreshRelevance 208\n",
      "Exponea 180\n",
      "Fera 132\n",
      "Nice (Shopify plugin) 80\n",
      "Qubit 73\n",
      "Credibly 67\n",
      "Recently 66\n",
      "ConvertCart 62\n",
      "Woocommerce Notification (Woocommerce plugin) 61\n",
      "Convertize 58\n",
      "Bunting 17\n",
      "Taggstar 4\n",
      "Boost (Wordpress plugin) 3\n",
      "Vitals 1\n"
     ]
    }
   ],
   "source": [
    "ONE_MILLION_DB = expanduser(\"/mnt/10tb2/census-release-normalized/stateless/2018-11_1m_stateless/2018-11_1m_stateless_census_crawl.sqlite\")\n",
    "\n",
    "adp_prevalence, adp_sites_dict = get_prevalence_counts(ADP_PROVIDER_DOMAINS, ONE_MILLION_DB)\n",
    "dump_as_json(adp_prevalence, \"adp-third-party-lib-prevalence-one-million-sites.json\")\n",
    "for endpoint_name, site_count in sorted(adp_prevalence.iteritems(), key=lambda x: x[1], reverse=True): \n",
    "    print endpoint_name, site_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
